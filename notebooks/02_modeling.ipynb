{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bccf2844",
   "metadata": {},
   "source": [
    "# Preprocessing IMDB Dataset for Sentiment Analysis with DistillBERT\n",
    "We will use DistillBERT, a smaller and faster version of BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88934ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification ,TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aace98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dataset['train']\n",
    "df_test = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d8548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d8548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8f6097",
   "metadata": {},
   "source": [
    "Load the DistillBERT tokenizer from the Hugging Face Transformers library and the data_collator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f6097",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db43fc",
   "metadata": {},
   "source": [
    "Define a preprocessing function that tokenizes the text data and prepares it for input into the DistillBERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8db43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532327f5",
   "metadata": {},
   "source": [
    "Apply to train and test using the `map` function \n",
    "\n",
    ">batched=True to process multiple samples at once for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757a37b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = df_train.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd116d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test = df_test.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd116d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_train)\n",
    "print(tokenized_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6811950a",
   "metadata": {},
   "source": [
    "Define metrics for evaluation using accuracy and f1 from the `evaluate` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d64197",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "f1_metric = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20586412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    print(eval_pred)\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eec62a",
   "metadata": {},
   "source": [
    "# Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4a8335",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4a5d5a",
   "metadata": {},
   "source": [
    "# Define training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68b2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/imdb-distilbert\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3413afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaef93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e57405",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "model.config.label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1} \n",
    "\n",
    "model.save_pretrained(\"../models/imdb-distilbert/checkpoint-3126\")\n",
    "tokenizer.save_pretrained(\"../models/imdb-distilbert/checkpoint-3126\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd5aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
